## Main scripts
1. dataset.py
* Contains the main pytorch dataset child class

2. model/nnunet.py
* Contains the implementation of the nn-Unet model used in this project

3. preprocessing.py
* Contains the class to preprocess the raw data
``python preprocessing.py -c "config/config.yaml"``

4. runtraining.py
* Script to train the model
``python runtraining.py -c "config/config.yaml"``

* Change the training to use DDP by modifying the script to call the ``RunDDP`` method in the train object
``train.RunDDP()``

5. config/config.yaml
* Configuration file used to control every process

6. train.py
* training script 

7. metrics/dice.py
* Contains the dice loss used for training

## Monitoring and Troubleshooting

1. data_exploration.ipynb
* find the smallest and largest volumes out of all the data

2. modelarch.ipynb
* List the parameters from the model given a config file

3. monitor_training.ipynb
* Plot the training loss, learning rates, cross entropy and dice scores at each iteration and epoch
* Need to input the paths to the training and validation reports

4. runtestset.ipynb
* Run model on test dataset
* Set path to saved model state dictionary in the ``cfile`` file
* Data directory will be the  ``test`` directory in ``data_dest`` in the ``cfile``
* Class labels will be inferred using the ``labels_src`` path in the ``cfile``
* Set device to use within the notebook itself

5. learningrates.ipynb
* Plot the learning rates given an optimizer and scheduler

6. testrun.ipynb
* Run model on random test set generated by a class
* The test set can be changed by modifying the ``TestRun`` class in ``testrun.py``

7. view_dataset.ipynb
* View images after data augmentation 
* Modify the ``train_dataset_params`` in the config file 
