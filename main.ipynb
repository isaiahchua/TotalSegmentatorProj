{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8fe641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from os.path import abspath, dirname, join, basename, isdir\n",
    "import json\n",
    "from addict import Dict\n",
    "import glob\n",
    "import yaml\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "import torch.multiprocessing as mp\n",
    "import timm\n",
    "import shutil\n",
    "import time\n",
    "from dataset import TotalSegmentatorData\n",
    "from train import Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4764ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = \"config/demo_config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96262081",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = Dict(yaml.load(open(CONFIG_FILE, \"r\"), Loader=yaml.Loader))\n",
    "paths = cfgs.paths\n",
    "data_cfgs = cfgs.dataset_params\n",
    "optim_cfgs = cfgs.optimizer_params\n",
    "schedule_cfgs = cfgs.scheduler_params\n",
    "model_cfgs = cfgs.model_params\n",
    "train_cfgs = cfgs.train_params\n",
    "test_cfgs = cfgs.test_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd55672",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e485792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveConfigFile(src, paths):\n",
    "    results_path = dirname(abspath(paths.model_ckpts_dest))\n",
    "    model_id = paths.model_ckpts_dest.split(\".\", 1)[0][-2:]\n",
    "    filename = basename(src).split(\".\", 1)[0] + \"_\" + model_id + \".yaml\"\n",
    "    cp_path = join(results_path, filename)\n",
    "\n",
    "    if not isdir(results_path):\n",
    "        os.makedirs(results_path)\n",
    "    shutil.copy(src, cp_path)\n",
    "\n",
    "def main(cfile):\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    torch.manual_seed(42)\n",
    "    cfgs = Dict(yaml.load(open(abspath(cfile), \"r\"), Loader=yaml.Loader))\n",
    "    SaveConfigFile(CONFIG_FILE, cfgs.paths)\n",
    "\n",
    "    train = Train(cfgs)\n",
    "    start = time.time()\n",
    "    train.RunDDP()\n",
    "    end = time.time()\n",
    "    print(\"\\n\")\n",
    "    start_s = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(start))\n",
    "    end_s = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(end))\n",
    "    time_taken = end - start\n",
    "    if time_taken > 3600.:\n",
    "        divisor = 3600.\n",
    "        suffix = \"hr\"\n",
    "    else:\n",
    "        divisor = 60.\n",
    "        suffix = \"min\"\n",
    "    print(f\"Start Time: {start_s}, End Time: {end_s}, Total Time Taken: {(time_taken)/divisor:.3f} {suffix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07d40cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/isaiah/.local/lib/python3.9/site-packages/torchio/transforms/augmentation/spatial/random_elastic_deformation.py:271: RuntimeWarning: The maximum displacement is larger than the coarse grid spacing for dimensions: [2], so folding may occur. Choose fewer control points or a smaller maximum displacement\n",
      "  warnings.warn(message, RuntimeWarning)\n"
     ]
    },
    {
     "ename": "ProcessRaisedException",
     "evalue": "\n\n-- Process 2 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/home/isaiah/TotalSegmentatorProj/train.py\", line 176, in _TrainModelDDP\n    p = self.model(inp)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 1040, in forward\n    output = self._run_ddp_forward(*inputs, **kwargs)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 1000, in _run_ddp_forward\n    return module_to_run(*inputs[0], **kwargs[0])\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/isaiah/TotalSegmentatorProj/model/nnunet.py\", line 142, in forward\n    out = self.decoder(features)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 204, in forward\n    input = module(input)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/isaiah/TotalSegmentatorProj/model/nnunet.py\", line 64, in forward\n    out = self.lrelu(self.norm1(self.conv1(out)))\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 613, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 608, in _conv_forward\n    return F.conv3d(\nRuntimeError: Given groups=1, weight of size [320, 640, 3, 3, 3], expected input[1, 320, 32, 16, 4] to have 640 channels, but got 320 channels instead\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG_FILE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(cfile)\u001b[0m\n\u001b[1;32m     18\u001b[0m train \u001b[38;5;241m=\u001b[39m Train(cfgs)\n\u001b[1;32m     19\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRunDDP\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/TotalSegmentatorProj/train.py:259\u001b[0m, in \u001b[0;36mTrain.RunDDP\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mRunDDP\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 259\u001b[0m     \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_TrainModelDDP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_gpus\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:240\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    236\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    237\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    238\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m start_method)\n\u001b[1;32m    239\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:198\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:160\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    158\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n\u001b[1;32m    159\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m original_trace\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[38;5;241m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 2 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/home/isaiah/TotalSegmentatorProj/train.py\", line 176, in _TrainModelDDP\n    p = self.model(inp)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 1040, in forward\n    output = self._run_ddp_forward(*inputs, **kwargs)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 1000, in _run_ddp_forward\n    return module_to_run(*inputs[0], **kwargs[0])\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/isaiah/TotalSegmentatorProj/model/nnunet.py\", line 142, in forward\n    out = self.decoder(features)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 204, in forward\n    input = module(input)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/isaiah/TotalSegmentatorProj/model/nnunet.py\", line 64, in forward\n    out = self.lrelu(self.norm1(self.conv1(out)))\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 613, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/home/sgteam/miniconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 608, in _conv_forward\n    return F.conv3d(\nRuntimeError: Given groups=1, weight of size [320, 640, 3, 3, 3], expected input[1, 320, 32, 16, 4] to have 640 channels, but got 320 channels instead\n"
     ]
    }
   ],
   "source": [
    "main(CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd8c8d3",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e2d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
